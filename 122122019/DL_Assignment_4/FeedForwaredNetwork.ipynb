{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b6f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as r\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f0c6d76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.linspace(-5.0, 5.0, 120)\n",
    "y = np.linspace(-5.0, 5.0, 120)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = np.sqrt(X**2 + Y**2)\n",
    "fig,ax=plt.subplots(1,1)\n",
    "cp = ax.contourf(X, Y, Z)\n",
    "\n",
    "ax.set_title('A filled contour plot')\n",
    "ax.set_xlabel('x (cm)')\n",
    "ax.set_ylabel('y (cm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bb3d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, shape, cost, activation_fn, dropout=False):\n",
    "\n",
    "        # cost function\n",
    "        self.cost = getattr(self, cost)\n",
    "        # activation function\n",
    "        self.activation_fn, self.dactivation_fn = None, None\n",
    "        self.set_activation_function(activation_fn)\n",
    "        # learning rate\n",
    "        self.learning_rate = None\n",
    "        # initialize all data containers involved in neural network training\n",
    "        self.input, self.target = None, None\n",
    "        self.act, self.dw_sum = None, None\n",
    "        self.w, self.b = None, None\n",
    "        self.dCdact, self.dCdw, self.dCdb = None, None, None\n",
    "        self.create_network_structure(shape)\n",
    "        # dropout regularizer\n",
    "        self.dropout, self.mask = None, None\n",
    "        self.set_dropout(dropout, shape)\n",
    "        # vanilla momentum and Nesterov momentum SGD\n",
    "        self.run_momentum, self.run_nesterov = None, None\n",
    "        self.v_dw, self.v_db = None, None\n",
    "        self.w_initial, self.b_initial = None, None\n",
    "        self.set_momentum(shape)\n",
    "        # ADAM optimizer\n",
    "        self.run_adam = None\n",
    "        self.iterations = None\n",
    "        self.s_dw, self.s_db = None, None\n",
    "        self.set_adam(shape)\n",
    "\n",
    "    # functions called implicitly when creating neural network\n",
    "\n",
    "    def set_adam(self, shape):\n",
    "        self.run_adam = False\n",
    "        self.iterations = 0\n",
    "        self.s_dw = np.array([np.zeros((shape[i + 1], shape[i])) for i in range(len(shape) - 1)])\n",
    "        self.s_db = np.array([np.zeros((1, shape[i]))[0] for i in range(1, len(shape))])\n",
    "\n",
    "    def set_momentum(self, shape):\n",
    "        self.run_momentum, self.run_nesterov = False, False\n",
    "        self.v_dw = np.array([np.zeros((shape[i + 1], shape[i])) for i in range(len(shape) - 1)])\n",
    "        self.v_db = np.array([np.zeros((1, shape[i]))[0] for i in range(1, len(shape))])\n",
    "        self.w_initial, self.b_initial = 0, 0\n",
    "\n",
    "    def set_dropout(self, dropout, shape):\n",
    "        self.dropout = dropout  # contains the keep probabilities for input and hidden layers\n",
    "        self.mask = np.array([np.full((1, shape[i]), 1)[0] for i in range(len(shape))])\n",
    "\n",
    "    def set_activation_function(self, activation_fn):\n",
    "        self.activation_fn = getattr(self, activation_fn)\n",
    "        self.dactivation_fn = getattr(self, 'd' + activation_fn)\n",
    "\n",
    "    def create_network_structure(self, shape):\n",
    "        self.input, self.target = 0, 0\n",
    "        self.act = np.zeros((1, len(shape)), dtype=object)[0]  # array of all activations in the neural network\n",
    "        self.dw_sum = np.zeros((1, len(shape) - 1), dtype=object)[0]  # array of all sigmoid'(weighted sum) in every neuron\n",
    "        self.w = np.array([np.random.randn(shape[i + 1], shape[i]) * np.sqrt(1 / shape[i]) for i in range(len(shape) - 1)])\n",
    "        self.b = np.array([np.full((1, shape[i]), 0)[0] for i in range(1, len(shape))])  # array of all biases in the neural network (keep same b for each minibatch)\n",
    "        self.dCdact = np.zeros((1, len(shape)), dtype=object)[0]  # array of all derivatives of cost function with respect to all individual activations\n",
    "        self.dCdw = np.array([np.full((shape[i + 1], shape[i]), 0) for i in range(len(shape) - 1)])  # cost gradient with respect to w\n",
    "        self.dCdb = np.array([np.full((1, shape[i]), 0)[0] for i in range(1, len(shape))])  # cost gradient with respect to b\n",
    "\n",
    "\n",
    "    # main training algorithm (propagation of error through network)\n",
    "\n",
    "    def forward_prop(self, *dropout_error_calc):\n",
    "        self.act[0] = np.array(self.input)\n",
    "        for l in range(len(self.w)):\n",
    "            self.dropout_forward(self.act[l], l, dropout_error_calc)\n",
    "            # compute all activations in layer (act_l)\n",
    "            act_l = np.tensordot(self.act[l], self.w[l], (0, 1)) + self.b[l]\n",
    "            self.dw_sum[l] = self.dactivation_fn(np.ravel(act_l))\n",
    "            self.act[l + 1] = self.activation_fn(np.ravel(act_l))\n",
    "\n",
    "    def backprop(self):\n",
    "        for l in range(len(self.act) - 1, 0, -1):\n",
    "            # fetch all dC/dact for current layer (dC/dact_l) and place into dC/dact array\n",
    "            dCdact_l = self.comp_dCdact(l)\n",
    "            self.dCdact[l] = dCdact_l\n",
    "            # calculate dC/dW for all weights in layer (dC/dw_l)\n",
    "            dCdw_l = np.matmul(np.transpose([self.act[l - 1]]), [self.dw_sum[l - 1]])\n",
    "            dCdw_l = np.multiply(dCdw_l, np.transpose(self.dCdact[l]))\n",
    "            # calculate dC/dB for all biases in layer (dC/db_l)\n",
    "            dCdb_l = np.multiply(self.dw_sum[l - 1], self.dCdact[l])\n",
    "            # set cost gradient\n",
    "            self.dCdw[l - 1] = np.transpose(dCdw_l)\n",
    "            self.dCdb[l - 1] = dCdb_l\n",
    "        self.dropout_back()\n",
    "\n",
    "    def comp_dCdact(self, l):\n",
    "        # special case for output layer\n",
    "        if l == len(self.act) - 1:\n",
    "            return self.cost()\n",
    "        # compute dCdact for inner layers\n",
    "        a = np.transpose(self.w[l])\n",
    "        b = self.dw_sum[l]\n",
    "        dAdact = np.multiply(a, b)\n",
    "        return np.matmul(dAdact, np.transpose(self.dCdact[l + 1]))\n",
    "\n",
    "    # cost functions\n",
    "\n",
    "    def cross_entropy(self):\n",
    "        self.dw_sum[-1] = np.full((1, len(self.dw_sum[-1])), 1)[0]\n",
    "        return np.subtract(self.act[-1], self.target)\n",
    "\n",
    "    def mean_squared(self):\n",
    "        return 2 * np.subtract(self.act[-1], self.target)\n",
    "\n",
    "    # function to call to train network\n",
    "\n",
    "    def train(self, file1, file2, epochs, batch_size, lr, lmbda=1, run_momentum=False, run_nesterov=False,\n",
    "              run_adam=False):\n",
    "        self.learning_rate = lr\n",
    "        self.run_momentum, run_nesterov, run_adam = run_momentum, run_nesterov, run_adam\n",
    "        data = self.file_to_data(file1, file2)\n",
    "        train_data, test_data = data[0], data[1]\n",
    "        # update arrays\n",
    "        dCdw_update, dCdb_update = 0, 0\n",
    "        # create new mask for dropout\n",
    "        self.new_mask()\n",
    "        for i in range(epochs):  # number of times train through entire training set\n",
    "            # randomize the training data\n",
    "            r.shuffle(train_data)\n",
    "            for j in range(len(train_data)):\n",
    "                # feed training example into network\n",
    "                self.input = train_data[j][1:]\n",
    "                self.target = np.zeros((1, 10))[0]\n",
    "                self.target[train_data[j][0]] = 1\n",
    "                self.forward_prop()\n",
    "                self.backprop()\n",
    "                dCdw_update += self.dCdw\n",
    "                dCdb_update += self.dCdb\n",
    "                # perform batch update (dependent on batch size)\n",
    "                if j % batch_size == 0 and j != 0 or j + 1 == len(train_data):\n",
    "                    # apply L2 regularizer during every minibatch update\n",
    "                    self.batch_update(dCdw_update, dCdb_update, batch_size)\n",
    "                    self.weight_decay(lmbda, len(train_data))\n",
    "                    # reset update arrays\n",
    "                    dCdw_update, dCdb_update = 0, 0\n",
    "                    # choose new neurons to be dropped\n",
    "                    self.new_mask()\n",
    "                    if j + 1 == len(train_data):\n",
    "                        print('Percent correct (Training):', self.error_calc(train_data))\n",
    "                        print('Percent correct (Testing) :', self.error_calc(test_data))\n",
    "                    self.nesterov_momentum(look_ahead=True)\n",
    "\n",
    "    # batch update for mini-batch gradient descent\n",
    "    def batch_update(self, dCdw_update, dCdb_update, batch_size):\n",
    "        self.dCdw = dCdw_update / batch_size\n",
    "        self.dCdb = dCdb_update / batch_size\n",
    "        if self.run_momentum:  # add momentum to batch update\n",
    "            self.momentum()\n",
    "        elif self.run_nesterov:\n",
    "            self.nesterov_momentum()\n",
    "        elif self.run_adam:\n",
    "            self.adam_optimizer()\n",
    "        else:\n",
    "            self.w -= self.learning_rate * self.dCdw\n",
    "            self.b -= self.learning_rate * self.dCdb\n",
    "\n",
    "    # calculating the error at end of every epoch\n",
    "    def error_calc(self, data):\n",
    "        num_correct = 0\n",
    "        for j in range(len(data)):\n",
    "            self.input = data[j][1:]\n",
    "            self.target = np.zeros((1, 10))[0]\n",
    "            self.target[data[j][0]] = 1\n",
    "            self.forward_prop(True)  # don't run dropout during testing\n",
    "            # error criteria\n",
    "            if np.argmax(self.act[-1]) == data[j][0]:\n",
    "                num_correct += 1\n",
    "        return num_correct / len(data)\n",
    "\n",
    "    # function to parse file data into programmable data\n",
    "    def file_to_data(self, file1, file2):\n",
    "        train_file = open(file1, 'r').readlines()\n",
    "        test_file = open(file2, 'r').readlines()\n",
    "        train_data = list()\n",
    "        test_data = list()\n",
    "        for line in train_file[1:]:  # skip header line\n",
    "            # convert all training data to normalized floating values using map()\n",
    "            train_input = list([int(line[0])]) + list(map(lambda x: float(x) / 255, line.split(',')[1:]))\n",
    "            # add to training data array\n",
    "            train_data.append(train_input)\n",
    "        for line in test_file[1:]:  # skip header line\n",
    "            # convert all test data to normalized floating values using map()\n",
    "            test_input = list([int(line[0])]) + list(map(lambda x: float(x) / 255, line.split(',')[1:]))\n",
    "            # add to test data array\n",
    "            test_data.append(test_input)\n",
    "        return train_data, test_data\n",
    "\n",
    "    # group of activation functions to choose from and their respective derivatives\n",
    "    def ReLU(self, sum):\n",
    "        sum[sum < 0] = 0\n",
    "        return sum\n",
    "\n",
    "    def dReLU(self, sum):\n",
    "        sum[sum > 0] = 1\n",
    "        sum[sum <= 0] = 0\n",
    "        return sum\n",
    "\n",
    "    def sigmoid(self, sum):\n",
    "        return 1 / (1 + np.e ** (-sum))\n",
    "\n",
    "    def dsigmoid(self, sum):\n",
    "        return (np.e ** (-sum)) / ((1 + np.e ** (-sum)) ** 2)\n",
    "\n",
    "    # L2 Regularizer\n",
    "    def weight_decay(self, lmbda, n):\n",
    "        scaling_factor = 1 - self.learning_rate * lmbda / n\n",
    "        # rescale the weights\n",
    "        self.w *= scaling_factor\n",
    "\n",
    "    # dropout regularizer and associated functions\n",
    "    def new_mask(self):\n",
    "        if not self.dropout:\n",
    "            return\n",
    "        for l in range(len(self.mask) - 1):\n",
    "            if l == 0:\n",
    "                keep_prob = self.dropout[0]\n",
    "            else:\n",
    "                keep_prob = self.dropout[1]\n",
    "            # apply inverted dropout\n",
    "            self.mask[l] = np.random.binomial(1, keep_prob, len(self.mask[l])) / keep_prob\n",
    "\n",
    "    def dropout_forward(self, act_l, l, dropout_error_calc):\n",
    "        if not self.dropout or bool(dropout_error_calc):\n",
    "            return\n",
    "        act_l *= self.mask[l]\n",
    "\n",
    "    def dropout_back(self):\n",
    "        if not self.dropout:\n",
    "            return\n",
    "        # update dCdb and dCdw to reflect dropped out neurons\n",
    "        self.dCdb *= self.mask[1:]\n",
    "        for l in range(len(self.dCdw)):\n",
    "            self.dCdw[l] = np.transpose(np.multiply(np.transpose(self.dCdw[l]), self.mask[l + 1]))\n",
    "\n",
    "    def bias_correction(self, beta, *args):\n",
    "        if not args:\n",
    "            return\n",
    "        for items in args:\n",
    "            items /= (1 - beta ** self.iterations)\n",
    "\n",
    "    def learning_rate_decay(self):\n",
    "        self.learning_rate /= np.sqrt(self.iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "372893e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct (Training): 0.9216833333333333\n",
      "Percent correct (Testing) : 0.9273\n",
      "Percent correct (Training): 0.9365333333333333\n",
      "Percent correct (Testing) : 0.9383\n",
      "Percent correct (Training): 0.9448833333333333\n",
      "Percent correct (Testing) : 0.9446\n",
      "Percent correct (Training): 0.9505166666666667\n",
      "Percent correct (Testing) : 0.9491\n",
      "Percent correct (Training): 0.9544\n",
      "Percent correct (Testing) : 0.9524\n"
     ]
    }
   ],
   "source": [
    "from NeuralNetwork import *\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # For training, parameters of 5 epochs, a mini batch size of 10, a learning rate of 0.1, and a l2 value 1.0 were used here.\n",
    "    NN = NeuralNetwork([784, 100, 10], cost='cross_entropy', activation_fn='sigmoid', dropout=(0.9, 0.5))\n",
    "    NN.train('mnist_train.csv', 'mnist_test.csv', 5, 10, 0.1, lmbda=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3bc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
